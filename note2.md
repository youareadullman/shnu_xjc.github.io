# 数据挖掘笔记2  

> @author：徐佳诚  

# 数据清洗  
  
在处理大量数据时，很少有数据整理完整的情况，往往存在缺失，我们可以忽视小部分的缺失，但大量缺失时会影响我们的结果，了解数据清洗必不可少。
数据缺失有很多种类：  

数据的完整性----例如人的属性中缺少性别、籍贯、年龄等  

数据的唯一性----例如不同来源的数据出现重复的情况  

数据的权威性----例如同一个指标出现多个来源的数据，且数值不一样  

数据的合法性----例如获取的数据与常识不符，年龄大于200岁  

数据的一致性----例如不同来源的不同指标，实际内涵是一样的，或是同一指标内涵不一致    


### 数据清洗的结果是对各种脏数据进行对应方式的处理，得到标准的、干净的、连续的数据，提供给数据统计、数据挖掘等使用。  

## 数据清洗方法 
解决高维度问题：降维（主成分分析，随机森林）  

解决维度低或缺少维度问题：抽象（各种汇总，平均、加总、最大、最小等，各种离散化，聚类、自定义分组等）  

解决多指标数值、单位不同问题：归一化（最小-最大，零-均值，小数定标）  

# 数据描述与可视化
分描述性、规范性和预测性可视化  

描述性分析：它描述已经发生的事情并提出其根本原因。便于读者更方便的了解数据与结果，便于创作者更形象化的看到自己的工作并再创作。  

规范性分析：能够使事情更上一层楼，除了帮助读者了解原因之外，它还帮助读者从发生的事情中学习并制定可改善其当前绩效和盈利能力的策略和策略；一个简单的例子就是对营销活动的分析。  

预测分析是最有益的，但可以说是最复杂的类型，它可以帮助用户识别出建议未来情况和行为的模式；使用预测分析，组织可以计划即将到来的方案，预测新趋势并为它们进行最有效和最具成本效益的准备；预测即将到来的趋势为优化组织从中获得的收益奠定了基础，使用可视化做出更明智的决策。  

# 特征选择
## 过程
1.收集更多数据  

2.通过正则化引入对复杂度的惩罚  

3.选择更少参数的简单模型  

4.对数据降维（降维有两种方式：特征选择和特征抽取）
## 三大类方法
Filter(过滤法)：按照发散性或相关性对各个特征进行评分，设定阈值或者待选择特征的个数进行筛选  

Wrapper(包装法)：根据目标函数（往往是预测效果评分），每次选择若干特征，或者排除若干特征  

Embedded(嵌入法)：先使用某些机器学习的模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征（类似于Filter，只不过系数是通过训练得来的）
LDA算法既可以用来降维，又可以用来分类，但是目前来说，主要还是用于降维。在我们进行图像识别图像识别相关的数据分析时，LDA是一个有力的工具。下面总结下LDA算法的优缺点。

# 线性判别分析

　　　　LDA算法的主要优点有：

　　　　1）在降维过程中可以使用类别的先验知识经验，而像PCA这样的无监督学习则无法使用类别先验知识。

　　　　2）LDA在样本分类信息依赖均值而不是方差的时候，比PCA之类的算法较优。

　　　　LDA算法的主要缺点有：

　　　　1）LDA不适合对非高斯分布样本进行降维，PCA也有这个问题。

　　　　2）LDA降维最多降到类别数k-1的维数，如果我们降维的维度大于k-1，则不能使用LDA。当然目前有一些LDA的进化版算法可以绕过这个问题。

　　　　3）LDA在样本分类信息依赖方差而不是均值的时候，降维效果不好。

　　　　4）LDA可能过度拟合数据。
